\documentclass[10pt]{amsart}
\usepackage[total={6.5in,9in},centering]{geometry}
\usepackage{amsmath}
\usepackage{graphicx} % for png figures
\usepackage{subcaption} % for subfigures
\usepackage{xfrac} % for sfrac (slanted inline fractions)
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage[super]{nth}
\usepackage[yyyymmdd]{datetime}
\renewcommand{\dateseparator}{-}
\usepackage{amsaddr} % addresses up front
%\usepackage{amssymb, amsmath, bm, nameref}
\pagenumbering{gobble} % no page numbers

\newcommand{\SETb}{SET\texttrademark\ } % this one has a space after
\newcommand{\SET}{SET\texttrademark}  % this one has no space, so it can be
                                      % followed by a comma or period

\newcommand{\SETSET}{{\sc setset}}
\newcommand{\SETSETb}{{\sc setset }}
\newcommand{\SETSETA}{{\sc setset-all}}
\newcommand{\SETSETAb}{{\sc setset-all }}
\newcommand{\ED}{{\sc enumerate\_deals}}
\newcommand{\EDb}{{\sc enumerate\_deals }}


\begin{document}


\title[SET Enumeration]{Complete Enumeration of the Game \SETb for up to 12 Cards}
\author[Settergren]{Reuben Settergren}
\email{rjs@jhu.edu}

\thanks{Thanks to Liz McMahon and Gary Gordon of Lafayette College for helpful
  correspondence during the development of this capability, as well as for
  writing the delightful book {\em The Joy of Set} \cite{JOS}.}

\thanks{Thanks also to the 6-\nth{7} grade Math Discovery Club at The Cambridge
  School (\url{cambridgeclassical.org}), who set me off on this journey.}

\maketitle

\begin{abstract}
For the card game \SET, the exact probabilities of all possible numbers of SETs
can be determined analytically for deals of small numbers of cards, and can be
enumerated exhaustively for somewhat larger numbers. But for 12 cards (the
starting number of cards according to the rules of \SET) combinatorial explosion
has so far prohibited direct enumeration, allowing only estimation of
probabilities by simulation. In this result, massively parallel programming on a
Graphical Processing Unit (GPU) is used to exhaustively enumerate all possible
deals of up to 12 cards, in about 100 hours. In particular, the probability that
an opening deal of 12 \SETb cards does not contain a SET is exactly
$2284535476080/70724320184700 \approx 3.2302\%$.
\end{abstract}

\section{Introduction}
In the card game \SET\cite{SET}, each card depicts 4 attributes (number,
texture, color, shape), and each attribute has 3 possible values, for a total of
$3^4=81$ cards. A `SET' is defined as a set\footnote{A note on terminology:
  \SETb will refer to the card game, `SET' will refer to a SET according to the
  rules of the game, and 'set' will take its normal mathematical sense of an
  unordered collection. A $k$-set (or for instance 5-set or 12-set) will refer
  to a set of $k$ cards.} of 3 cards for which all attributes are either all the
same, or all different. A fundamentally important fact about SETs is that, for
any two distinct cards, there is a unique third card which completes a SET with
them. The unique SET-mate of any two cards can be constructed by setting all
four attributes appropriately: if the first two cards have the attribute the
same, set the third the same; if they are different, set the third card's
attribute different.

The card game is equivalent to the finite geometry AG(4,3) (integers in 4
dimensions, modulo 3); cards are analogous to points, and SETs are lines (sets
of collinear points). In solid geometry, a plane can be constructed from a set
of 3 non-collinear points, by repeatedly adding to the set all points which are
collinear with points already in the set, until closure is reached (all
collinear points are already in the set). Similarly, a `plane' in \SETb can be
built from 3 cards which do not form a SET, by repeatedly adding cards which
form SETs with 2 previous cards. Closure will be reached at 9 cards, at which
point all pairs of cards will have their SET-mate. The number of SETs in a plane
is 12. See \cite{JOS} for extensive discussion of planes, hyperplanes, and the
relationship between \SETb and affine geometry in general.

Another equivalent formulation of the card game is that cards are 4-tuples from
the set $\{0,1,2\}^4$, and a SET is three cards such that their sum is $\equiv
(0,0,0,0) \pmod{3}$. Even more briefly, the 4-tuples can be represented by
4-digit numbers in base 3; the 81-cards in the \SETb deck are represented by
ternary numbers 0000, 0001, 0002, 0010, \ldots 2222. For any two cards, their
unique SET-mate can be found by choosing each attribute/digit so that the digit
sum is $\equiv 0 \pmod{3}$.

The rules of \SETb specify that a game begins by dealing 12 cards. So the
question naturally arises, what is the probability that 12 cards have no SET? Or
more generally, {\bf What is the probability distribution of all possible
  numbers of SETs that 12 cards may contain?} That is the question addressed by
this work.

If the initial deal has no SETs, additional cards are dealt (three at a time)
until a SET is found. How far could this process go? It turns out that this
question was answered before the game of \SETb was created. The affine geometry
analogue of a maximal collection of SET cards with no SET is called a `maximal
cap', and in 1971 it was proven that the size of maximal caps in AG(4,3) is 20
\cite{MAXCAP}. Since the largest possible collection of cards with no SET is 20,
in the vanishingly unlikely case that a game of SET reaches 21 cards, there will
definitely be a SET.  This provides a useful bound for how far to extend
analysis of how many cards contain how many SETs; larger numbers of cards can
never occur in a (well-played) game of \SET.

\section{Previous Results}
A complete enumeration of all 12-card sets must consider $\binom{81}{12} \approx
7\times 10^{13}$ cases. McMahon, Gordon et al note (\cite{JOS} p.~259) that,
even though their computer program can process about 100 million deals per hour,
a complete enumeration would still take 80 years. Enumeration, they note,
``might be feasible with streamlined code and faster machines or parallel
processing.''

Donald Knuth tackled the more specific problem of counting how many deals have 0
SETs. Knuth achieves tremendous speedup over exhaustive enumeration by using
``isomorph rejection'' (i.e. `streamlined code'). Knuth called his program to
find SETless $k$-sets, \SETSETb \cite{SETSET}. 

For instance, using the 4-digit ternary representation, the first 1-card deal is
$\{0000\}$. Trivially, that 1-card set does not contain a SET; but more
importantly, every other single-card set also does not contain a set, by
isomorphism with the first one. Because of this isomorphism, \SETSETb was able to
reject the other cards along with the first, as an isomorphism group all
together.

\SETSETb conducted a depth-first search of all sets of size up to 21, but was
able to prune that search whenever:
\begin{itemize}
\item Adding another card to the previous introduces a SET, or
\item Adding another card forms a set which is isomorphic to a
  previously-accounted for SETless set.
\end{itemize}
In this way, \SETSETb was able to count all the SETless sets within
$\Sigma_{k=1}^{21}\binom{81}{k}\approx 2.04\times 10^{19}$ sets, by inspecting
only $5.14\times 10^8$ cases, and avoiding inspection of isomorphic
cases. Running \SETSETb on a Core i7 2.7GHz processor takes about four and a half
hours.

The `secret sauce' of \SETSETb is in what `isomorphic' means, and how to
determine whether one set is isomorphic to another. Five years later (in an
improved solution called \SETSETAb \cite{SETSET-ALL}), Knuth realized he could
expand the sense of the isomorphisms, thus increasing the size of the
isomorphism groups, and decreasing their number, which decreases the number of
cases to consider. For instance, while \SETSETb considered 128 isomorphism groups
for sets of size $k=4$, \SETSETAb dealt with only 2. In total, \SETSETAb dealt
with only 9606 isomorphism groups, and thus had drastically improved speed,
reaching the same answers as \SETSETb in just 3m45s (on the same hardware).

For 3 and 4 cards, the only posibilities are 0 SETs, or 1 SET, so a complete
picture can be obtained by subtracting the 0-SET counts from
$\binom{81}{k}$. But with the addition of a 5th card, it becomes possible to
have 0, 1, or 2 SETs. \SETSETb counts (as does direct combinatorial analysis)
that there are 22441536 5-sets with 0 SETs, but since \SETSETb prunes its search
as soon as a first SET is encountered, it does not divide the remaining
$\binom{81}{5}-22441536=3180060$ 5-sets into how many have 1 SET or 2
SETs. Combinatorial analysis is able to determine that the 3180060 divides up as
3116880 with 1 SET and 63180 with 2 SETs (\cite{JOS}, pp.~56-58). This
combinatorial analysis, however cannot be extended all the way to $k=12$,
because the analysis grows infeasibly complex.

\SETSET's analysis of the 0-SET problem is complete, in that it provides counts
of 0-SET $k$-sets for $k$ up to 21, and \cite{MAXCAP} guarantees that for
$k>=21$ there are no more SETless sets. The numbers of SETless sets for
$k=3\ldots 12$ provide useful benchmarks for verifying this work, giving
confidence in the correctness of the counts for the number of sets with 1 SET, 2
SETs, etc. In particular our enumeration will match the \SETSETb result of
2284535476080 SETless 12-sets, which is of interest to \SETb enthusiasts.


\section{Implementation}
This paper picks up the implicit challenge of McMahon and Gordon to code the
12-card enumeration with streamlined code and parallel processing (although not
necessarily faster machines). The program is called \ED, and source code is
available on GitHub \cite{ME}. \EDb can be run serially, or in parallel using
threads or OpenCL \cite{OPENCL} kernels. Note that OpenCL can be configured so
that its kernels can be parallelized onto either CPU or GPU resources.

For each set of $k$ cards, all $\binom{k}{3}$ triples need to be checked for
whether they constitute a SET. Knuth notes, ``We will frequently need to find
the third card of a SET, given any two distinct cards $x$ and $y$, so we store
the answers in a precomputed table.''  This is an immense computational savings
compared to 4 sums and 4 modulo 3's for each SET determination, so \EDb adopts
that practice here as well.

Sets of $k$ cards are enumerated according to a combinatorial numbering
system. The forward sense of combinatorial numbering computes, for any
particular $k$-set, where it 'ranks' in the enumeration of all $\binom{81}{k}$
$k$-sets. The inverse process starts with an enumeral number $N$, and 'unranks'
it into the $k$-set which occupies that place in the numbering system. The first
iteration of \EDb used the unranking algorithm presented in \cite{WIKI}. In
order to unrank a combinatorial number $N$ into $k$ specific cards, the
algorithm requires, for each of the $k$ cards, a number of comparisons to
$\binom{n}{k}$, for $n\le 81, k\le 12$. To avoid $O(k)$ computation each for
each binomial coefficient, those values were also precomputed and stored in a
lookup table.

The number of lookups of $\binom{n}{k}$ required to unrank a particular number
$N$ into a $k$-set varies. The fixed number of 81 cards establishes an upper
bound on the possible number of lookups per card being unranked, so the
complexity of this unranking algorithm is $O(k)$. The code was temporarily
instrumented to empirically count the average number of steps, and it was
determined that the constant for this linear complexity (the average number of
$\binom{n}{k}$ lookups for unranking a $k$-set) is $C\approx 45$. (This could be
improved by switching to a binary search of the binomial table, but the need for
non-branching code (see immediately below) obviates this computational approach
anyways.)

In a later iteration of \ED, a combination-incrementing algorithm was
implemented, with no branching (GPU programs are most efficient if there are no
{\tt if} or {\tt while} statements, because simultaneous kernels execute the
same line of code together, and kernels that take different paths through the
code have to wait for each other). Instead of fully-unranking each combination
from its enumeral number, \EDb reuses the previous combination by incrementing
it to the next combination in the series. Because of the avoidance of branching,
the combination-increment algorithm takes exactly the same number of steps to
increment any combination. The algorithm executes 5 lines of code for each of
the $k$ cards in the combination, so the incrementing algorithm is also
$O(k)$. The algorithm is not 9x faster, however, since the 5 lines are more
complex than the simple steps taken in the above unranking
algorithm. Empirically, the speedup from switching to full unranking to
incrementation was 2-3x (even serially).

The goal for this paper was to enumerate 12-card deals, which requires
enumeration of combinations numbered by integers as large as $\binom{81}{12}
\approx 7\times 10^{13}$. For this purpose, an unsigned 64-bit integer
suffices. Fortunately, the latest advances in GPU technology have recently
introduced native capabilty for 64-bit integer types. Also fortuitous is the
fact that, since $2^{64} > \binom{81}{21}$, 64-bit unsigned integers suffice all
the way up to deals of 21 cards (the natural limit for this analysis, since no
game of \SETb can ever need more than 21 cards at once).

This problem is `embarassingly parallel': the processing for any $k$-set, or
consecutive range of $k$-sets, is completely independent, and the inputs and
outputs are both independent and small. The input is merely an enumeral number
(or two numbers defining a range), and the output a small array of accumulators,
counting how many $k$-sets in the range have 0 SETs, 1 SET, \ldots 14 SETs (it
is known that 14 is the maximum number of SETs that can occur in 12 cards
\cite{VINCI}, \cite{JOS} p.~281). Each kernel can have its own small array of
accumulators, to avoid write contention, and the separate accumulators can be
then quickly summed. Doubling the available computing resources should halve the
processing time.

\section{Results}
\subsection{Exhaustive Enumeration}
\EDb was run for $3<=k<=12$. The results are presented in Table
\ref{THE_TABLE}. Runtimes are for GPU processing on an NVIDIA Quadro
P4000. Non-rigorous trial and error determined that a decent setting for the GPU
processing was to queue 5000 kernels at a time, each tasked with enumerating a
batch of 10000 $k$-combinations.

The 12-set enumeration took 90.1h=3.75d. The total time for $k=3\ldots 12$ was
104.5h=4.35d. (Because of combinatorial explosion, the 12-card enumeration
consumed the lion's share of processing.) The 12-card processing rate was 218M
deals/second, and the overall rate was 226M/second (\EDb is faster for smaller
$k$, because fewer triples need to be checked for each set). Single-threaded on
a Core i7 2.7GHz CPU, the 12-card enumeration ran at 842K/s (projected
exhaustive enumeration time 972d=2.66y). Thus GPU processing yielded a
218M/842K$\approx$256x speedup (at least comparing these specific processors).
However, the Quadro P4000 has 1792 cores, so it seems possible that the GPU
processing could be further optimized to obtain a 12-card enumeration time well
under 24 hours. Enumeration for $k=13$ or maybe 14 may become worthwhile, but
combinatorial explosion quickly wins again, as runtimes increase about 7x for
each larger $k$. Perhaps Knuth's isomorphism rejection technique could be
extended to counting not just 0-SET deals, making possible exhaustive
enumeration up to $k=21$ or possibly even $k=81$.

\begin{table}
  \caption{Enumeration Results}\label{THE_TABLE}
  \centering
  \begin{tabular}{r | r r r r r r }
    & \multicolumn{6}{c}{Number of cards} \\
    \hline\hline
    SETs & 3 & 4 & 5 & 6 & 7 & 8   \\
    \hline
0  & 84240 & 1579500 & 22441536 & 247615056 & 2144076480 & 14587567020  \\
1  & 1080 & 84240 & 3116880 & 71772480 & 1137240000 & 12981215520 \\
2  &  &  & 63180 & 5068440 & 184485600 & 3996514080 \\
3  &  &  &  & 84240 & 11372400 & 573168960 \\
4  &  &  &  &  &  & 22744800 \\
5  &  &  &  &  & 42120 & 3032640 \\
6  &  &  &  &  &  &  \\
7  &  &  &  &  &  &  \\
8  &  &  &  &  &  & 10530 \\
\hline
$\binom{81}{N}$ & 85320 & 1663740 & 25621596 & 324540216 & 3477216600 & 32164253550  \\
\hline
seconds & 0.001 & 0.002 & 0.045 & 0.56 & 6.3 & 69 
  \end{tabular}

  \vskip 5mm

  \begin{tabular}{r | r r r r }
    SETs & 9 & 10 & 11 & 12 \\
    \hline
0  & 77541824880 & 318294370368 & 991227481920 & 2284535476080 \\
1  & 108956689920 & 676366666560 & 3091339021680 & 10266579666720 \\
2  & 56941354080 & 557948898000 & 3829696640640 & 18459179294400 \\
3  & 15417548640 & 253318946400 & 2704419900000 & 19278240770880 \\
4  & 1857807900 & 62354111040 & 1144078603200 & 12746054337120 \\
5  & 160729920 & 9176162112 & 306795509280 & 5650817178240 \\
6  & 11119680 & 827405280 & 49231877760 & 1649199670560 \\
7  & & 78848640 & 6382949040 & 330527433600 \\
8  & 758160 & 23882040 & 729349920 & 48500063820 \\
9  &  & 3032640 & 243622080 & 8323838640 \\
10 &  &  & 21228480 & 2091005280 \\
11 &  &  & & 160729920 \\
12 & 1170 & 84240 & 2611440 & 86346000 \\
13 &  &  & 379080 & 21340800 \\
14 &  &  &  & 3032640 \\
\hline
$\binom{81}{N}$ & 260887834350 & 1878392407320 & 12124169174520 & 70724320184700 \\
\hline
seconds & 646 & 5697 & 45298 & 324480
  \end{tabular}
\end{table}

A number of interesting features arise from the full pattern of counts. Some
numbers are repeated in the table.

The first value in the table, 84240 (the number of 3-deals with 0 SETs) also
shows up as the number of 4-deals with 1 SET. Both times the value is 1080*78,
but for different reasons. The number of 3-deals with 1 SET (the number of
3-deals which {\em are} a SET) is just 1080. But whenever two of the 81 cards
are dealt, there are 79 remaining cards -- one of which completes a SET and 78
of which do not. So the number of 0-SET triples are 78 times as many as 1-SET
triples. However, every 4-deal with 1 SET is a 3-deal with 1 SET, plus one more
card. After a SET is laid out, there are 78 remaining cards which could be added
to form a 1-SET 4-deal. So the number of 1-SET 4-deals is also 78 times as mny
as 1-SET triples.

Overall, the value of 84240 shows up 4 times, 3032640 three times, and 160729920
twice. This invites questions such as, is there a meaningful bijection between
the 9-sets with 5 SETs, and the 12-sets with 11 SETs? Or is it just a
coincidence from combinatorial reuse of the same prime factors? The table is
full of multiples of 1080, and also of 1170 (the number of planes (9-sets with
12 SETs)).

\begin{figure}[!htb]
  \center{\includegraphics[width=\textwidth]{kset_curves.png}}
  \caption{\label{FIGCOLS} Each curve is one deal size (table column); x is
    number of SETs, y is probability.}
\end{figure}

To visualize Table \ref{THE_TABLE}, it is necessary to normalize the data in
each column to probabilities (dividing column $k$ by $\binom{81}{k}$), otherwise
each successive $k$ has results an order of magnitude larger, and the data are
not visually comparable. Figure \ref{FIGCOLS} renders the data with one curve
per table column (per deal size $k$), and Figure \ref{FIGROWS} in transpose ---
one curve per number of SETs. 

Figure \ref{FIGCOLS} graphs each column of the table (deal size $k$) as one
curve. The horizontal axis is number of SETS, and the vertical axis is again
probability (above, in linear scale, and below in log scale). The curves for
$k=3$ (highest on the left) and $k=4$ have only two datapoints each, since the
only possibilities for those cases are 0 SETs or 1 SET. $k=5$ introduces the
possibility of two SETs, and thus a third data point. $k=9$ is the smallest deal
size for which 0 SETs is not the most likely outcome. For $k=12$ (of interest to
players of \SET), the most likely occurrences are 3 SETs (27.25\%), and 2 SETs
(26.10\%), together accounting for a small majority of 12-card deals.

Past $k=6$ SETs, all the curves are indistinguishably near 0 in the linear-scale
graph, which illustrates that in actual game play, players will practically
never encounter configurations with more than 6 SETs. The log-scale graph,
however, reveals the structure at smaller probabilities.

There are a number of gaps in the table indicating impossible numbers of SETs
for some set sizes. These gaps can also be seen in the logarithmic graph in
Figure \ref{FIGCOLS}. The first occurrence of a gap is at $k$=7 cards, at 4
SETs. This shows that 7 cards can have 0, 1, 2, 3, or 5 SETs, but not exactly 4
SETs. It is possible to have 3 SETs in 6 cards, but that is a kind of tipping
point; there is no way to add a \nth{7} card and complete only one more SET. The
\nth{7} card completes either two new SETs, or none.\footnote{There are 84240
  3-SET 6-sets, and 42120 5-SET 7-sets. Is there a meaningful decomposition of
  the 3-SET 6-sets such that for exactly half of them a \nth{7} card can trigger
  2 additional SETs?}

It is also interesting to note that, corresponding to every gap in Figure
\ref{FIGCOLS}, the subsequent curve 'sags' into that gap. For instance, the
7-card curve has its gap at 4 SETs, and the 8-card curve has a deflection
downwards at 4 SETs. (So just as the probability of 4 SETs in 7 cards is smaller
than expected (small all the way down to 0!), the probability of 4 SETs in 8
cards is also a little smaller than expected). Similar deflections are apparent
in the 10-card curve above the 8- and 9-card gap at 7 SETs\footnote{This major
  deflection in the 10-card curve seems also to be echoed in the 11-card curve
  at 8 SETs, and the 12-card curve at 9 SETs.}, and in the 12-card curve above
the 9- and 10-card gap at 11 SETs.

Note also that every occurrence of a gap for $k$ cards is followed by a gap in
the $k+1$ cards series that is smaller by one. It's as if, whenever there is a
tipping point of cards ripe for creating additional SETs, adding additional
cards creates an avalanche that fills in the gap.

The gaps in the 9-card enumeration are particularly interesting. The 1170 9-sets
with 12 SETs are the complete collection of all possible planes (this matches
the analytical result obtained in \cite{JOS}, p.~48). It is possible for 9 cards
to have 8 SETs, as explained by Liz McMahon:\footnote{Co-author of \cite{JOS},
  personal correspondence}
\begin{quote}
If you take a plane [12 SETs] and remove one card, what's left has 8 SETs.  You
can then add another point that doesn't complete any more SETs, and that gives
you the 8 SETs in 9 cards.
\end{quote}
Between 8 and 12 SETs though, no intermediate number of SETs is possible for 9
cards.

\begin{figure}[!htb]
  \center{\includegraphics[width=\textwidth]{nSET_curves.png}}
  \caption{\label{FIGROWS} Each curve is one number of SETs (table row); x is
    deal size, y is probability.}
\end{figure}

In Figure \ref{FIGROWS}, each curve represents the probability of a certain
number of SETs (one row of the table). The horizontal axis is the number of
cards dealt, and the vertical axis is probability. The curve for 0 SETs starts
at $84240/85320\approx 98.7\%$ for 3 cards, and only decreases as more cards are
dealt. If the graph were to be extended to a deal size of $k=21$, the 0 SETs
curve would reach $0\%$ exactly, but within this range it decreases at $k=12$ to
$2284535476080/70724320184700\approx 3.23\%$ (the figure of most interest to
players of \SET).

The gaps evident in Figure \ref{FIGCOLS} become in Figure \ref{FIGROWS} curves
that `start later'. The first gap at 7 cards and 4 SETs now says that, although
5 SETs is possible with 7 cards, in order to have exactly 4 SETs, 8 or more
cards is necessary. And although 12 SETs is possible with only 9 cards (again,
that would be a plane), 11 SETs cannot occur until 12 cards.

The 1-SET curve in Figure \ref{FIGROWS} shows that the probability of exactly 1
SET increases for a while, as more cards are dealt; but it peaks at $k=9$, and
then falls off as it becomes more likely that 2 or more SETs will occur. The 2
SET curve peaks at $k=11$. The 3 SET curve reaches its maximum within this range
at $k=12$, and random-sampling for $k>12$ indicates that 12 cards is indeed the
peak probability for 3 SETs.\footnote{The probability of 3 SETs in 12 cards is
  exactly $19278240770880/\binom{81}{12}\approx 0.2726$, and the sampled
  probability of 3 SETs in 13 cards is $246100265/10^9\approx 0.2461$.}

\begin{figure}[!htb]
  \center{\includegraphics[width=\textwidth]{kset_curves_full.png}}
  \caption{\label{FIGCOLSFULL} Each curve is one deal size (randomly sampled $k>12$
    are dashed lines); x is number of SETs, y is probability.}
\end{figure}

\begin{figure}[!htb]
  \center{\includegraphics[width=\textwidth]{nSET_curves_full.png}}
  \caption{\label{FIGROWSFULL} Each curve is one number of SETs; x is deal size
    (extended to include randomly-sampled $k=13\ldots 21$), y is probability.}
\end{figure}

\subsection{Random Sampling}
In addition to the complete enumerations of numbers of sets for $k=3\ldots 12$,
\EDb can be run in a random-sampling mode. For $k=13\ldots 21$, \EDb was run
over $10^9$ (one billion) randomly-sampled deals of size $k$. Figures
\ref{FIGCOLSFULL} and \ref{FIGROWSFULL} extend Figures \ref{FIGCOLS} and
\ref{FIGROWS} by adding the randomly-sampled results. Note that, in the
log-scale graphs, the bottom two light gray lines mark probabilities of $10^9$
and $10^8$ (i.e. 1 or 10 samples encountered in the sample size of 1 billion).

Since these extended results are subject to sampling error, they are not
provided in full here in this article, but they can be examined in the file {\tt
  enumerate\_deals.csv} on github \cite{ME}. Generally, the extended graphs
appear to smoothly extrapolate the patterns evident from the fully-enumerated
data. It is beyond the scope of this paper to quantify the statistical
significance or margin of error of these sampled values, but with a sample size
of $10^9$, all probabilities below $10^8$ are certainly suspect.

One interesting note about Figure \ref{FIGCOLSFULL} is that the $k=18$ is the
largest deal size for which 0 SETs were found (11 instances out of 1 billion
random samples). The $k=19$ series begins with 8 1-SET deals, and the $k=20$
curve begins with 1 sampled deal with 2 SETs. As discussed before, there are
'maximal caps' of 20 cards that contain 0 SETs, but their probability is so
small that the sample of $10^9$ did not encounter any. Indeed, \SETSETb tells us
there are exactly 632344 SET-less 20-sets, so the probability of encountering one
randomly is $632344/\binom{81}{20}\approx1.347\times 10^{-13}$. And since there
exist 20-sets with 0 SETS, there exist also 19-sets with 0 SETs (just remove any
of the 20 cards), but the random sample was also not large enough to encounter
any by chance.

For $k=21$, 13 out of $10^9$ deals had 4 SETs, but no deals (in the sample) had
fewer SETs. We know there can be no occurrences of 0 SETs in 21 cards, but could
there be 1 or 2 or 3 SETs? Or are some of those a gap after a 20-card
tipping-point? The gap/sag pattern discussed above seems to appear in multiple
locations in Figure \ref{FIGCOLSFULL}

On the right side of the graph, for large numbers of SETs, all probabilities are
similarly too small to make certain inferences. 1 billion deals of $k=21$ cards
encountered only 1 occurrence each of 41 and 46 SETs. Might there be a a gap
from 42 to 45 SETs? In fact there is not. Running \EDb in exhaustive mode, for
just the first 10 billion 21-card deals, turned up 24 deals with 41 SETs, 2
deals with 46 SETs, but also 3 with 42 SETs, 2 with 44 SETs, and 1 with 47
SETs. (This leaves open the possibiity -- but by no means certainty -- that 43
and 45 are gaps for 21-card deals) The reason so many more high-SET sets
appeared, is that the earliest deals in the enumeral series contain cards that
are very near each other, which means the cards have much more attribute
similarity than for a randomly-sampled deal. In fact, \cite{VINCI} indicates
that a maximum of 54 SETs is possible within 21 cards. But sampling just 1 or 10
billion out of $\combin{81}{21}\approx 1.36\times 10^{19}$ 21-deals is
vanishingly unlikely to encounter such a configuration.

%% Probabilities of $10^{-9}$ indicate a single sample
%% encountered, surely we cannot infer with any certainty that there is a gap at 21
%% cards from 42 to 45 SETs.

%% But what about 20 cards and 37 SETs? Certainly with only 3 total occurrences of
%% 36 and 38 SETs in 20 cards, it would not be surprising for 37 SETs to have
%% similar probability, and randomly not occur in 1 billion samples. However, note
%% the sag in the 21-card curve at 38 SETs. This seems similar to the gap/sag
%% pattern observed in the complete-enumeration data above, except occurring
%% `after' the putative gap in the 20-curve, rather than directly `above'
%% it. Perhaps this is an indication that there is actually a gap in the 20-curve
%% at 37 SETs.
%% \footnote{Or perhaps it is an indication of a sharp dropoff to a very small
%%   probability, not a pure gap (probability 0). A number of deflections in
%%   randomly-sampled curves are evident, but a little different than gap/sag
%%   pattern observed above.  13 cards sags at 15 SETs (right after 12 cards ends
%%   at 14 SETs); 18 cards sags at 27 SETs, right after 17 cards takes an apparent
%%   90\% dive in probability between 25 SETs and 26-30 SETs. The 19- and 20-card
%%   curves sag at 31 and 32 SETs, respectively, but not in response to any obvious
%%   probability drop in the 18-card curve in that neighborhood.}

\section{Conclusion}
This paper improves on the speed of enumeration of starting deals for the card
game \SET, to accomplish exhaustive enumeration for up to 12 cards, in a little
over 4 days. As the marginal factor for extra time spent is about 7x for each
additional card, the same hardware and software could enumerate 13, 14, and 15
cards in about 1 month, 7 months, and 4 years, respectively. To reach a complete
analysis at 21 cards, computational power would have to grow by many orders of
magnitude; or an analytical or non-exhaustive enumerative solution would have to
be devised (perhaps along the lines of Donald Knuth's
isomorphism-rejection-based enumerations of the 0-SET problem).



\begin{thebibliography}{9} % 1-digit reference nums


\bibitem{SETSET}Knuth, Donald E., {\sc setset} (1996), Documented programs in
  CWEB, from
  \url{https://www-cs-faculty.stanford.edu/~knuth/programs/setset.w}. Accessed
  \today.

\bibitem{SETSET-ALL}Knuth, Donald E., {\sc setset-all} (2001), Documented
  programs in CWEB, from
  \url{https://www-cs-faculty.stanford.edu/~knuth/programs/setset-all.w}. Accessed
  \today.

\bibitem{JOS} McMahon, Liz, Gary Gordon, et al, 2016. {\em The Joy of SET: The
  Many Mathematical Dimensions of a Seemingly Simple Card Game}, Princeton
  University Press, Princeton NJ.

\bibitem{OPENCL} Open Computing Language (OpenCL), from {\tt
  khronos.org/opencl}, accessed \today.

\bibitem{MAXCAP}Pellegrino, G., 1971. ``Sul massimo ordine delle calotte in
  $S_{4,3}$'' [{\em The maximal order of the shperical cap in $S_{4,3}$}], {\em
  Matematiche} {\bf 25}, pp 149-157.

\bibitem{SET} SET Enterprises, Inc. \url{https://www.setgame.com}

\bibitem{ME}Settergren, Reuben, 2019. \url{https://github.com/RubeRad/SET}
  
\bibitem{VINCI}Vinci, Jim, 2009. ``The maximum number of sets for $n$ cards and
  the total number of internal sets for all partitions of the deck,'' on the
  \SETb game website at
  \url{https://www.setgame.com/sites/default/files/teacherscorner/SETPROOF.pdf},
  accessed \today.

\bibitem{WIKI} Wikipedia article ``Combinatorial Number System,'' \url{https://en.wikipedia.org/wiki/Combinatorial_number_system#Finding_the_k-combination_for_a_given_number},
  accessed \today.

\end{thebibliography}
 
\end{document}
